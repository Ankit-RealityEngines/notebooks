{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook 2: Abacus.AI API Streaming Feature Store",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0ejrLq_-Zl6"
      },
      "source": [
        "## How-to guide Streaming Feature Store on the Abacus.AI platform\n",
        "This notebook provides you with a hands on environment to build and deploy a feature store using Abacus.AI\n",
        "\n",
        "We'll be using the [Retail Interaction Logs](https://s3.amazonaws.com/abacusai.exampledatasets/pers_promotion/events.csv) and [Item Categories](https://s3.amazonaws.com/abacusai.exampledatasets/pers_promotion/item_categories.csv) datasets, which contain information about user interactions and item attributes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIhrIhXeqJJE"
      },
      "source": [
        "1. Install the Abacus.AI library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSsm7EQrmvey"
      },
      "source": [
        "!pip install abacusai\n",
        "!pip install fsspec\n",
        "!pip install s3fs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD5QL0lJsBga"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izrh6I2aqlTa"
      },
      "source": [
        "2. Add your Abacus.AI [API Key](https://abacus.ai/app/profile/apikey) generated using the API dashboard as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8TJ_-Qamz5x"
      },
      "source": [
        "#@title Abacus.AI API Key\n",
        "\n",
        "api_key = 'cf45d23272e74465b776e5fa79101f7b'  #@param {type: \"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqpb-UfFqmzs"
      },
      "source": [
        "3. Import the Abacus.AI library and instantiate a client."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8M1MoB0m1DV"
      },
      "source": [
        "from abacusai import ApiClient, ApiException\n",
        "client = ApiClient(api_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tXzo8ZRqodi"
      },
      "source": [
        "## 1. Create a Project\n",
        "\n",
        "In this notebook, we're going to create and deploy a feature store that automatically featurizes input data using the Item Categorials and a streamed retail interactions log."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8idfft0im5ci"
      },
      "source": [
        "project = client.create_project(name='Demo Feature Store Streaming Project', use_case='FEATURE_STORE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS8T5vcLrIlg"
      },
      "source": [
        "## 2. Creating Datasets\n",
        "\n",
        "Using the Create Dataset API, we can tell Abacus.AI the public S3 URI of where to find our batch dataset.\n",
        "- [Items Dataset](https://s3.amazonaws.com/abacusai.exampledatasets/pers_promotion/item_categories.csv)\n",
        "This dataset contains information about the item categories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_Ccd2iIm0sX"
      },
      "source": [
        "### Data Preview\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "qDK9JNZ0m2Er",
        "outputId": "7e1ca4f4-7efd-43ef-fb96-6489b85dcfd6"
      },
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('s3://abacusai.exampledatasets/pers_promotion/item_categories.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itemid</th>\n",
              "      <th>categoryid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>1171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24</td>\n",
              "      <td>1244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40</td>\n",
              "      <td>160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59010</th>\n",
              "      <td>466847</td>\n",
              "      <td>1221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59011</th>\n",
              "      <td>466848</td>\n",
              "      <td>1250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59012</th>\n",
              "      <td>466849</td>\n",
              "      <td>464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59013</th>\n",
              "      <td>466858</td>\n",
              "      <td>1191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59014</th>\n",
              "      <td>466861</td>\n",
              "      <td>1051</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59015 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       itemid  categoryid\n",
              "0          19        1171\n",
              "1          24        1244\n",
              "2          25          72\n",
              "3          40         160\n",
              "4          42          84\n",
              "...       ...         ...\n",
              "59010  466847        1221\n",
              "59011  466848        1250\n",
              "59012  466849         464\n",
              "59013  466858        1191\n",
              "59014  466861        1051\n",
              "\n",
              "[59015 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R3p7tAkrwPv"
      },
      "source": [
        "### Add the datasets to Abacus.AI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mDVrJYKrzB9"
      },
      "source": [
        "Using the Create Dataset API, we can tell Abacus.AI the public S3 URI of where to find the datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Asz9GAiLHJQn"
      },
      "source": [
        "# if the datasets already exist, skip creation\n",
        "try: \n",
        "  items_dataset = client.describe_dataset(client.describe_feature_group_by_table_name('items_categories').dataset_id)\n",
        "  streaming_dataset_items = client.describe_dataset(client.describe_feature_group_by_table_name('streaming_item_interactions').dataset_id)\n",
        "  batch_events_dataset = client.describe_dataset(client.describe_feature_group_by_table_name('events_batch_data').dataset_id)\n",
        "except ApiException: # datasets not found\n",
        "  items_dataset = client.create_dataset_from_file_connector(name='Items Dataset', table_name='items_categories', location='s3://abacusai.exampledatasets/pers_promotion/item_categories.csv')\n",
        "  streaming_dataset_items = client.create_streaming_dataset(name='Item Interactions', \n",
        "                                                            table_name='streaming_item_interactions')\n",
        "  batch_events_dataset = client.create_dataset_from_file_connector(name='Item Interactions Batch Data', \n",
        "                                                                 table_name='events_batch_data', \n",
        "                                                                 location='s3://abacusai.exampledatasets/pers_promotion/events.csv')\n",
        "  items_dataset.wait_for_inspection()\n",
        "  batch_events_dataset.wait_for_inspection()\n",
        "\n",
        "streaming_feature_group = client.describe_feature_group_by_table_name(table_name=streaming_dataset_items.feature_group_table_name)\n",
        "items_feature_group = client.describe_feature_group_by_table_name(table_name=items_dataset.feature_group_table_name)\n",
        "batch_feature_group = client.describe_feature_group_by_table_name(table_name=batch_events_dataset.feature_group_table_name)\n",
        "\n",
        "items_feature_group.add_to_project(project.project_id)\n",
        "streaming_feature_group.add_to_project(project.project_id)\n",
        "batch_feature_group.add_to_project(project.project_id)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvT_qOdprKzp"
      },
      "source": [
        "items_feature_group.set_indexing_config(primary_key='itemid')\n",
        "batch_feature_group.set_indexing_config(update_timestamp_key='timestamp')\n",
        "streaming_dataset_items.set_streaming_retention_policy(retention_hours=48, retention_row_count=2_000_000_000)\n",
        "streaming_feature_group.set_schema([{'name': 'timestamp', 'dataType': 'DATETIME'}, \n",
        "                                    {'name': 'itemid', 'dataType': 'STRING'}, \n",
        "                                    {'name': 'event', 'dataType': 'STRING'}, \n",
        "                                    {'name': 'visitorid', 'dataType': 'STRING'}])\n",
        "streaming_feature_group.set_indexing_config(lookup_keys=['visitorid'], update_timestamp_key='timestamp')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-lnw8eyrcNl"
      },
      "source": [
        "### Stream data to the streaming dataset\n",
        "\n",
        "We'll first test streaming some mock data, invalidate that, then upload real data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I9a8h8ttKzI"
      },
      "source": [
        "import time\n",
        "streaming_tokens = client.list_streaming_tokens()\n",
        "if streaming_tokens:\n",
        "  streaming_token = streaming_tokens[0].streaming_token\n",
        "else:\n",
        "  streaming_token = client.create_streaming_token().streaming_token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCZ9BWiLxsLt"
      },
      "source": [
        "streaming_feature_group.append_data(streaming_token=streaming_token, \n",
        "                                    data={'visitorid': '123', 'itemid': '1', 'event': 'click', 'timestamp': time.time()})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__gawFoRyFKM"
      },
      "source": [
        "streaming_feature_group.invalidate_streaming_data(invalid_before_timestamp=time.time())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQpSnJXxxo4B"
      },
      "source": [
        "To get some real data, we're going to load the data from a batch dataset locally and stream it all into the new streaming dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4zOu9UMrpj0"
      },
      "source": [
        "import pandas as pd\n",
        "raw_event_data = pd.read_csv('s3://abacusai.exampledatasets/pers_promotion/events.csv')\n",
        "raw_event_data['visitorid'] = raw_event_data.index\n",
        "raw_event_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C3A0E_Lsa9M"
      },
      "source": [
        "from numpy import isnan\n",
        "for row in raw_event_data.head(10).to_dict(orient=\"records\"):\n",
        "    row['event_timestamp'] =  time.time()\n",
        "    row['visitorid'] = str(row['visitorid'])\n",
        "    if isnan(row['transactionid']):\n",
        "        row['transactionid'] = None\n",
        "    streaming_feature_group.append_data(streaming_token=streaming_token, data=row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PQdlF-HWfrz"
      },
      "source": [
        "Verify recently streamed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjmw4nCpWh_u"
      },
      "source": [
        "streaming_feature_group.get_recent_streamed_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu5reOzojzmD"
      },
      "source": [
        "### Concatenate Batch with streaming\n",
        "\n",
        "If you have a batch dataset like above, it's more efficient to load it into Abacus.AI first and the streaming feature group data into the batch dataset (or vice versa)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ugIoEQVjzQZ"
      },
      "source": [
        "from datetime import datetime\n",
        "batch_feature_group.concatenate_data(streaming_feature_group.feature_group_id, \n",
        "                                         merge_type='UNION', \n",
        "                                         replace_until_timestamp=datetime(2021, 9, 1).timestamp())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIIxOKVxzmEo"
      },
      "source": [
        "## Join Metadata with Feature Group Data\n",
        "\n",
        "We can join batch with streaming either with SQL or a python feature group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn17EkJAzwwp"
      },
      "source": [
        "### Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFv_IxYNzyDa"
      },
      "source": [
        "function_code = '''\n",
        "import pandas as pd\n",
        "\n",
        "def join_tables(events_df, items_df):\n",
        "    return pd.merge(events_df, items_df, on='itemid')\n",
        "'''\n",
        "python_feature_group = client.create_feature_group_from_function(table_name='python_interactions_joined_items', \n",
        "                                                                 function_source_code=function_code, \n",
        "                                                                 function_name='join_tables', \n",
        "                                                                 input_feature_groups=['events_batch_data', 'items_categories'])\n",
        "python_feature_group.add_to_project(project.project_id)\n",
        "python_feature_group.set_schema([{'name': 'timestamp', 'dataType': 'DATETIME'}, \n",
        "                                    {'name': 'itemid', 'dataType': 'STRING'}, \n",
        "                                    {'name': 'categoryid', 'dataType': 'STRING'}, \n",
        "                                    {'name': 'visitorid', 'dataType': 'STRING'},\n",
        "                                    {'name': 'event', 'dataType': 'STRING'},\n",
        "                                    {'name': 'transactionid', 'dataType': 'STRING'}])\n",
        "python_feature_group.set_indexing_config(lookup_keys=['visitorid'], update_timestamp_key='timestamp')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKsa6mrT1Ooz"
      },
      "source": [
        "### SQL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RzlgP5ej64W"
      },
      "source": [
        "feature_group = client.create_feature_group(table_name='interactions_joined_items', sql='SELECT * FROM events_batch_data JOIN items_categories USING (itemid)')\n",
        "feature_group.set_indexing_config(lookup_keys=['visitorid'])\n",
        "feature_group.add_to_project(project.project_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9zdfMpRLRB3"
      },
      "source": [
        "### Materialize Feature Group Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ompwZJ4nLkqw"
      },
      "source": [
        "feature_group_version = feature_group.create_version()\n",
        "feature_group_version.wait_for_results()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx4JE8stMCkp"
      },
      "source": [
        "feature_group_version.load_as_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1ZjBprIEIzw"
      },
      "source": [
        "### Deploy feature group for online featurization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZleD66xQnCY_"
      },
      "source": [
        "deployment_token = client.create_deployment_token(project_id=project.project_id).deployment_token\n",
        "deployment = client.create_deployment(feature_group_id=feature_group.feature_group_id, project_id=project.project_id) \n",
        "deployment.wait_for_deployment()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVEBK_UenDXB"
      },
      "source": [
        "client.lookup_features(deployment_id=deployment.deployment_id, deployment_token=deployment_token, query_data={'visitorid': ['466806', '273888']})"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}