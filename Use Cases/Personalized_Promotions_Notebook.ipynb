{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0ejrLq_-Zl6"
   },
   "source": [
    "## How-to guide for Personalized Promotions use-case on Abacus.AI platform\n",
    "This notebook provides you with a hands on environment to build a model that creates personalized promotions using the Abacus.AI Python Client Library.\n",
    "\n",
    "We'll be using the [Retail Interaction Logs](https://s3.amazonaws.com//realityengines.exampledatasets/pers_promotion/events.csv) and [Item Categories](https://s3.amazonaws.com//realityengines.exampledatasets/pers_promotion/item_categories.csv) datasets, which contain information about user interactions and item attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIhrIhXeqJJE"
   },
   "source": [
    "1. Install the Abacus.AI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSsm7EQrmvey",
    "outputId": "22a00ee3-f4c5-4065-bbf3-8da72ce6a1f4"
   },
   "outputs": [],
   "source": [
    "!pip install abacusai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1o5pJlfiqjuz"
   },
   "source": [
    "We'll also import pandas and pprint tools for visualization in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ki_Nt6xBmyws"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # A tool we'll use to download and preview CSV files\n",
    "import pprint # A tool to pretty print dictionary outputs\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izrh6I2aqlTa"
   },
   "source": [
    "2. Add your Abacus.AI [API Key](https://abacus.ai/app/profile/apikey) generated using the API dashboard as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "d8TJ_-Qamz5x"
   },
   "outputs": [],
   "source": [
    "#@title Abacus.AI API Key\n",
    "\n",
    "api_key = '2fdecde877dc45fab937eff82b70eff0'  #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqpb-UfFqmzs"
   },
   "source": [
    "3. Import the Abacus.AI library and instantiate a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U8M1MoB0m1DV",
    "outputId": "9c9280ce-f5af-4c67-9762-fd809661d654"
   },
   "outputs": [],
   "source": [
    "from abacusai import ApiClient\n",
    "client = ApiClient(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tXzo8ZRqodi"
   },
   "source": [
    "## 1. Create a Project\n",
    "\n",
    "Abacus.AI projects are containers that have datasets and trained models. By specifying a business **Use Case**, Abacus.AI tailors the deep learning algorithms to produce the best performing model catered specifically for your data.\n",
    "\n",
    "We'll call the `list_use_cases` method to retrieve a list of the Use Cases currently available on the Abacus.AI platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nfe-W0KDm1-4",
    "outputId": "66395bc3-e2ec-4933-9b55-7f8866ec17e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UseCase(use_case='UCPLUGANDPLAY',\n",
       "   pretty_name='Plug & Play Your Tensorflow Model',\n",
       "   description='Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!'),\n",
       " UseCase(use_case='EMBEDDINGS_ONLY',\n",
       "   pretty_name='Vector Matching Engine',\n",
       "   description='Upload embeddings and leverage our similarity search infrastructure.. Scale to high traffic, update your index in near realtime'),\n",
       " UseCase(use_case='MODEL_WITH_EMBEDDINGS',\n",
       "   pretty_name='Tensorflow Model With Vector Matching Engine',\n",
       "   description='Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!'),\n",
       " UseCase(use_case='TORCH_MODEL_WITH_EMBEDDINGS',\n",
       "   pretty_name='PyTorch Model With Vector Matching Engine',\n",
       "   description='Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!'),\n",
       " UseCase(use_case='PYTHON_MODEL',\n",
       "   pretty_name='Custom Python Model',\n",
       "   description='Upload your training code and let Abacus.AI handle training. Host your models on our infrastructure and get a JSON api with auto scaling and more!'),\n",
       " UseCase(use_case='DOCKER_MODEL',\n",
       "   pretty_name='Plug & Play Your Dockerized Model',\n",
       "   description='Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!'),\n",
       " UseCase(use_case='DOCKER_MODEL_WITH_EMBEDDINGS',\n",
       "   pretty_name='Plug & Play Your Dockerized Model with Vector Matching Engine',\n",
       "   description='Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!'),\n",
       " UseCase(use_case='CUSTOMER_CHURN',\n",
       "   pretty_name='Customer Churn Prediction',\n",
       "   description='Identify customers who are most likely to churn out of your system and send them marketing promotions/emails to retain them. Deploy a real-time deep learning model that identifies customers who are most likely to leave and increase retention.'),\n",
       " UseCase(use_case='ENERGY',\n",
       "   pretty_name='Real-Time Forecasting',\n",
       "   description='Accurately forecast energy or computation usage in real-time. Make downstream planning decisions based on your predictions. We use generative modeling (GANs) to augment your dataset with synthetic data. This unique approach allows us to make accurate predictions in real-time, even when you have little historical data.'),\n",
       " UseCase(use_case='FINANCIAL_METRICS',\n",
       "   pretty_name='Financial Metrics Forecasting',\n",
       "   description='Accurately plan your cash flow, revenue, and sales with state-of-the-art deep learning-based forecasting. We use generative modeling (GANs) to augment your dataset with synthetic data. This unique approach allows us to make accurate predictions, even when you have little historical data.'),\n",
       " UseCase(use_case='FRAUD_ACCOUNT',\n",
       "   pretty_name='Account Takeover and Defense',\n",
       "   description=\"Shield your customers from account takeovers by blocking bots and fake sign-ups. Behind the scenes, our AI engine will develop a custom deep learning model to prevent bot attacks and stops account takeovers in real-time. Setup is super simple and doesn't require any engineering or cumbersome data preparation.\"),\n",
       " UseCase(use_case='FRAUD_THREAT',\n",
       "   pretty_name='Intelligent Threat Detection',\n",
       "   description=\"Stop breachers in their tracks by continuously monitoring your environment for malicious activity. Prevent alert fatigue by reducing the number of false positives over time. Behind the scenes, our AI engine develops a deep learning model customized for your data to continuously monitors all your logs and alerts you of any malicious activity. Setup is super simple and doesn't require any ML expertise.\"),\n",
       " UseCase(use_case='FRAUD_TRANSACTIONS',\n",
       "   pretty_name='Transaction/Credit Card Fraud',\n",
       "   description=\"Accept payments with confidence, reduce chargebacks, and catch payment fraud instantly as it happens. Behind the scenes, our AI engine develops a custom deep learning model for you that prevents transaction fraud and catches fraudsters in real-time. Set up is super simple and doesn't require any engineering and cumbersome data preparation.\"),\n",
       " UseCase(use_case='OPERATIONS_CLOUD',\n",
       "   pretty_name='Cloud Spend Alerts',\n",
       "   description='Deploy state-of-the-art deep learning models to monitor your cloud spend, spot anomalies, spot runaway incidents, mitigate cost incidents, and get alerts so they can be remedied as quickly as possible. Use deep learning to find anomalies in your cloud usage and get alerts on them to mitigate cost incidents.'),\n",
       " UseCase(use_case='CLOUD_SPEND',\n",
       "   pretty_name='Cloud Spend Alerts',\n",
       "   description='Deploy state-of-the-art deep learning models to monitor your cloud spend, spot anomalies, spot runaway incidents, mitigate cost incidents, and get alerts so they can be remedied as quickly as possible. Use deep learning to find anomalies in your cloud usage and get alerts on them to mitigate cost incidents.'),\n",
       " UseCase(use_case='TIMESERIES_ANOMALY_DETECTION',\n",
       "   pretty_name='Timeseries Anomaly Detection',\n",
       "   description='Spot anomalies in your time series data by using deep learning models to increase revenue, save costs and reduce risks. With Abacus.AI you can set up state of the art deep learning models for time series anomaly detection within hours. These models adjust in real time and spot both simple one dimensional and complex multidimensional anomalies. Our models also help you find the root cause of the anomalies. No cumbersome data preparation or engineering effort to deploy the models in production are required.'),\n",
       " UseCase(use_case='OPERATIONS_MAINTENANCE',\n",
       "   pretty_name='Predictive Maintenance',\n",
       "   description='Leverage deep learning models to proactively assess the health of your assets and perform timely maintenance to reduce downtime and save costs. With Abacus.ai you can set up state of the art deep learning models for predictive maintenance within hours. These models learn from your past failures as well as spot anomalies that can lead to new failures. No cumbersome data preparation or engineering effort to deploy the models in production is required.'),\n",
       " UseCase(use_case='PERS_PROMOTIONS',\n",
       "   pretty_name='Personalized Promotions',\n",
       "   description='Send personalized promotions to your customers and increase engagement. Personalize promotions based on catalog items, marketing messages, delivery channels, and discount terms. Deploy a real-time deep learning model that targets relevant promotions to customers and increases engagement. No cumbersome data preparation required and setup is super easy.'),\n",
       " UseCase(use_case='PREDICTING',\n",
       "   pretty_name='Predictive Modeling',\n",
       "   description='Use historical data to predict future occurrences. Train state-of-the-art predictive models customized specifically according to your data and deploy it in production in hours, not months!. You can create a deep learning model for your specific needs simply by pointing us to your data and specifying the inputs/outputs. Our expert AI engine will do the data cleaning and processing, algorithm selection (classification or regression), and model creation. You will be ready to generate intelligent predictions from the deployed model in production in just a few hours.'),\n",
       " UseCase(use_case='RETAIL',\n",
       "   pretty_name='Demand Forecasting',\n",
       "   description='Accurately forecast retail demand. We use generative modeling (GANs) to augment your dataset with synthetic data. This allows us to make accurate predictions even when you have little historical data.'),\n",
       " UseCase(use_case='SALES_FORECASTING',\n",
       "   pretty_name='Sales and Revenue Forecasting',\n",
       "   description='Forecast sales and revenue across your sales reps, products, business units, and locations. Use deep learning to forecast your sales across multiple dimensions. Make better planning discussions and anticipate future problems so you can mitigate them.'),\n",
       " UseCase(use_case='SALES_SCORING',\n",
       "   pretty_name='Predictive Lead Scoring',\n",
       "   description='Identify the sales leads that are most likely to convert into paying customers and increase revenue. Just point our AI engine to your data, and it will create a deep learning model customized for your data to score all your leads and identify the best ones for conversion.'),\n",
       " UseCase(use_case='USER_RANKINGS',\n",
       "   pretty_name='Personalized Search',\n",
       "   description='Re-rank search results or list of items based on a user preferences. Maximize user engagement and revenue. Our unique blend of reinforcement learning and deep learning-based technology works even when you have little historical data and have to deal with a fast-changing catalog or multiple new users.'),\n",
       " UseCase(use_case='NAMED_ENTITY_RECOGNITION',\n",
       "   pretty_name='Text extraction and classification',\n",
       "   description='Find and label fields within text documents such as emails, chats, receipts, invoices or any other unstructured data set. With Abacus.AI you can set up state of the art deep learning models for text extraction and classification within hours. Based on your specific domain and use-case, Abacus.AI can fine-tune pre-trained models, apply transfer learning or simply train new language models from scratch.  No cumbersome data preparation or engineering effort to deploy the models in production are required.'),\n",
       " UseCase(use_case='USER_RECOMMENDATIONS',\n",
       "   pretty_name='Personalized Recommendations',\n",
       "   description='Increase user engagement and revenue with personalized recommendations on your app/website. Our unique blend of reinforcement learning and deep learning-based technology works even when you have little historical data and have to deal with a fast-changing catalog or multiple new users.'),\n",
       " UseCase(use_case='USER_RELATED',\n",
       "   pretty_name='Related Items',\n",
       "   description='Maximize revenue and user engagement. Immerse your customers into your app/website by providing them with a rich browse and related items experience. Our unique blend of reinforcement learning and deep learning-based technology works even when you have little historical data and have to deal with a fast-changing catalog or multiple new users.'),\n",
       " UseCase(use_case='VISION',\n",
       "   pretty_name='Image Classification & Detection',\n",
       "   description='Train an image classification & detection model specific to your domain and use it to classify and detect relevant objects. With Abacus.AI you can set up state of the art deep learning models for Image classification & detection within hours. Based on your specific domain and use-case, Abacus.AI can fine-tune pre-trained models, apply transfer learning or simply train new vision models from scratch. No cumbersome data preparation or engineering effort to deploy the models in production are required.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_use_cases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWSjEJ7AqrQW"
   },
   "source": [
    "In this notebook, we're going to create a model that returns personalized promotions using the Retail Interaction Logs and Item Categories datasets. The 'PERS_PROMOTIONS' use case is best tailored for this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Si4FbtqCm3HN"
   },
   "outputs": [],
   "source": [
    "#@title Abacus.AI Use Case\n",
    "\n",
    "use_case = 'PERS_PROMOTIONS'  #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fy5OjU1yrD4W"
   },
   "source": [
    "By calling the `describe_use_case_requirements` method we can view what datasets are required for this use_case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFVAXGEdm4Q-",
    "outputId": "4f31b730-958f-4f94-dcd6-b35b335cfc87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'allowed_feature_mappings': { 'ACTION_TYPE': { 'allowed_feature_types': [ 'CATEGORICAL'],\n",
      "                                                 'description': 'This is an '\n",
      "                                                                'optional '\n",
      "                                                                'column that '\n",
      "                                                                'specifies the '\n",
      "                                                                'type of '\n",
      "                                                                'action the '\n",
      "                                                                'user took. '\n",
      "                                                                'This could '\n",
      "                                                                'include any '\n",
      "                                                                'action that '\n",
      "                                                                'is specific '\n",
      "                                                                'to you (e.g., '\n",
      "                                                                'view, click, '\n",
      "                                                                'purchase, '\n",
      "                                                                'rating, '\n",
      "                                                                'comment, '\n",
      "                                                                'like, etc). '\n",
      "                                                                'You can '\n",
      "                                                                'always upload '\n",
      "                                                                'a dataset '\n",
      "                                                                'that has no '\n",
      "                                                                'action_type '\n",
      "                                                                'column if all '\n",
      "                                                                'the actions '\n",
      "                                                                'in the '\n",
      "                                                                'dataset are '\n",
      "                                                                'the same '\n",
      "                                                                '(e.g., a '\n",
      "                                                                'dataset of '\n",
      "                                                                'only '\n",
      "                                                                'purchases or '\n",
      "                                                                'clicks).',\n",
      "                                                 'required': False},\n",
      "                                'ACTION_WEIGHT': { 'allowed_feature_types': [ 'NUMERICAL'],\n",
      "                                                   'description': 'This is an '\n",
      "                                                                  'optional '\n",
      "                                                                  'column that '\n",
      "                                                                  'specifies '\n",
      "                                                                  'the weight '\n",
      "                                                                  'of the '\n",
      "                                                                  'action '\n",
      "                                                                  '(e.g., '\n",
      "                                                                  'video watch '\n",
      "                                                                  'time, price '\n",
      "                                                                  'of item '\n",
      "                                                                  'purchased). '\n",
      "                                                                  'This is '\n",
      "                                                                  'used to '\n",
      "                                                                  'optimize '\n",
      "                                                                  'the the '\n",
      "                                                                  'model to '\n",
      "                                                                  'maximize '\n",
      "                                                                  'actions '\n",
      "                                                                  'with this '\n",
      "                                                                  'value.',\n",
      "                                                   'required': False},\n",
      "                                'IGNORE': { 'description': 'Ignore this column '\n",
      "                                                           'in training',\n",
      "                                            'multiple': True,\n",
      "                                            'required': False},\n",
      "                                'ITEM_ID': { 'allowed_feature_types': [ 'CATEGORICAL'],\n",
      "                                             'description': 'This is the '\n",
      "                                                            'unique identifier '\n",
      "                                                            'of each item in '\n",
      "                                                            'your catalog. '\n",
      "                                                            'This is typically '\n",
      "                                                            'your product id, '\n",
      "                                                            'article id, or '\n",
      "                                                            'the video id.',\n",
      "                                             'required': True},\n",
      "                                'TIMESTAMP': { 'allowed_feature_types': [ 'TIMESTAMP'],\n",
      "                                               'description': 'The timestamp '\n",
      "                                                              'when a '\n",
      "                                                              'particular '\n",
      "                                                              'action '\n",
      "                                                              'occurred.',\n",
      "                                               'required': False},\n",
      "                                'USER_ID': { 'allowed_feature_types': [ 'CATEGORICAL'],\n",
      "                                             'description': 'This is a unique '\n",
      "                                                            'identifier of '\n",
      "                                                            'each user in your '\n",
      "                                                            'user base.',\n",
      "                                             'required': True}},\n",
      "  'allowed_nested_feature_mappings': None,\n",
      "  'dataset_type': 'USER_ITEM_INTERACTIONS',\n",
      "  'description': 'This dataset corresponds to all the user-item interactions '\n",
      "                 'on your website or application. For example, all the actions '\n",
      "                 '(e.g. click, purchase, view) taken by a particular user on a '\n",
      "                 'particular item (e.g product, video. article) recorded as a '\n",
      "                 'time-based log.',\n",
      "  'name': 'User-Item Interactions',\n",
      "  'required': True}\n",
      "{ 'allowed_feature_mappings': { 'IGNORE': { 'description': 'Ignore this column '\n",
      "                                                           'in training',\n",
      "                                            'multiple': True,\n",
      "                                            'required': False},\n",
      "                                'ITEM_ID': { 'allowed_feature_types': [ 'CATEGORICAL'],\n",
      "                                             'description': 'This is a unique '\n",
      "                                                            'identifier of '\n",
      "                                                            'each item in your '\n",
      "                                                            'catalog. This is '\n",
      "                                                            'typically your '\n",
      "                                                            'product id, '\n",
      "                                                            'article id, or '\n",
      "                                                            'video id.',\n",
      "                                             'required': True},\n",
      "                                'PREDICTION_RESTRICT': { 'allowed_feature_types': [ 'CATEGORICAL'],\n",
      "                                                         'description': 'This '\n",
      "                                                                        'is an '\n",
      "                                                                        'optional '\n",
      "                                                                        'column '\n",
      "                                                                        'that '\n",
      "                                                                        'is '\n",
      "                                                                        'used '\n",
      "                                                                        'to '\n",
      "                                                                        'restrict '\n",
      "                                                                        'predictions '\n",
      "                                                                        'to '\n",
      "                                                                        'items '\n",
      "                                                                        'matching '\n",
      "                                                                        'a '\n",
      "                                                                        'specific '\n",
      "                                                                        'value '\n",
      "                                                                        'of '\n",
      "                                                                        'this '\n",
      "                                                                        'column. '\n",
      "                                                                        'If '\n",
      "                                                                        'this '\n",
      "                                                                        'is '\n",
      "                                                                        'set, '\n",
      "                                                                        'then '\n",
      "                                                                        'the '\n",
      "                                                                        'prediction '\n",
      "                                                                        'api '\n",
      "                                                                        'call '\n",
      "                                                                        'will '\n",
      "                                                                        'require '\n",
      "                                                                        'that '\n",
      "                                                                        'a '\n",
      "                                                                        'includeFilter '\n",
      "                                                                        'specifying '\n",
      "                                                                        'a '\n",
      "                                                                        'value '\n",
      "                                                                        'for '\n",
      "                                                                        'this '\n",
      "                                                                        'column '\n",
      "                                                                        'be '\n",
      "                                                                        'included.',\n",
      "                                                         'required': False}},\n",
      "  'allowed_nested_feature_mappings': None,\n",
      "  'dataset_type': 'CATALOG_ATTRIBUTES',\n",
      "  'description': 'This dataset corresponds to all the information you have in '\n",
      "                 'your catalog. If you want to recommend actions instead of '\n",
      "                 'items to users, you are welcome to upload an action catalog.',\n",
      "  'name': 'Catalog Attributes',\n",
      "  'required': None}\n",
      "{ 'allowed_feature_mappings': { 'IGNORE': { 'description': 'Ignore this column '\n",
      "                                                           'in training',\n",
      "                                            'multiple': True,\n",
      "                                            'required': False},\n",
      "                                'USER_ID': { 'allowed_feature_types': [ 'CATEGORICAL'],\n",
      "                                             'description': 'The unique '\n",
      "                                                            'identifier for '\n",
      "                                                            'the user.',\n",
      "                                             'required': True}},\n",
      "  'allowed_nested_feature_mappings': None,\n",
      "  'dataset_type': 'USER_ATTRIBUTES',\n",
      "  'description': 'This dataset corresponds to all the attributes or meta-data '\n",
      "                 'that you have about your user base. Any user profile '\n",
      "                 'information will be relevant here.',\n",
      "  'name': 'User Attributes',\n",
      "  'required': None}\n"
     ]
    }
   ],
   "source": [
    "for requirement in client.describe_use_case_requirements(use_case):\n",
    "  pp.pprint(requirement.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgUjI-wJrF9c"
   },
   "source": [
    "Finally, let's create the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8idfft0im5ci",
    "outputId": "e93a10d7-4f72-4eba-fbca-5f785e0a12ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project_id': '1e58b9d68',\n",
       " 'name': 'Personalized Promotions Project',\n",
       " 'use_case': 'PERS_PROMOTIONS',\n",
       " 'created_at': '2021-11-24T18:54:44+00:00',\n",
       " 'feature_groups_enabled': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promotions_project = client.create_project(name='Personalized Promotions Project', use_case=use_case)\n",
    "promotions_project.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OGCXiCkOwyb"
   },
   "source": [
    "**Note: When feature_groups_enabled is False then the use case does not support feature groups (collection of ML features). Therefore, Datasets are created at the organization level and tied to a project to further use them for training ML models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS8T5vcLrIlg"
   },
   "source": [
    "## 2. Add Datasets to your Project\n",
    "\n",
    "Abacus.AI can read datasets directly from `AWS S3` or `Google Cloud Storage` buckets, otherwise you can also directly upload and store your datasets with Abacus.AI. For this notebook, we will have Abacus.AI read the datasets directly from a public S3 bucket's location.\n",
    "\n",
    "We are using two datasets for this notebook. We'll tell Abacus.AI how each dataset should be used when creating it by tagging the dataset with a special Abacus.AI **Dataset Type**.\n",
    "- [Retail Interaction Logs](https://s3.amazonaws.com//realityengines.exampledatasets/pers_promotion/events.csv) (**USER_ITEM_INTERACTIONS**): \n",
    "This dataset contains information about visitor interactions, with data such as the visitor ID, event, timestamp, etc.\n",
    "- [Item Categories](https://s3.amazonaws.com//realityengines.exampledatasets/pers_promotion/item_categories.csv) (**CATALOG_ATTRIBUTES**): This dataset contains information about items with specified IDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2R3p7tAkrwPv"
   },
   "source": [
    "### Add the datasets to Abacus.AI\n",
    "\n",
    "First we'll use Pandas to preview the file, then add it to Abacus.AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "fXY1bRUpHBm3",
    "outputId": "c9e79103-6e71-45be-9f01-9d9878edf1ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1433221332117</td>\n",
       "      <td>257597</td>\n",
       "      <td>view</td>\n",
       "      <td>355908</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1433224214164</td>\n",
       "      <td>992329</td>\n",
       "      <td>view</td>\n",
       "      <td>248676</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1433221999827</td>\n",
       "      <td>111016</td>\n",
       "      <td>view</td>\n",
       "      <td>318965</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1433221955914</td>\n",
       "      <td>483717</td>\n",
       "      <td>view</td>\n",
       "      <td>253185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1433221337106</td>\n",
       "      <td>951259</td>\n",
       "      <td>view</td>\n",
       "      <td>367447</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756096</th>\n",
       "      <td>1438398785939</td>\n",
       "      <td>591435</td>\n",
       "      <td>view</td>\n",
       "      <td>261427</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756097</th>\n",
       "      <td>1438399813142</td>\n",
       "      <td>762376</td>\n",
       "      <td>view</td>\n",
       "      <td>115946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756098</th>\n",
       "      <td>1438397820527</td>\n",
       "      <td>1251746</td>\n",
       "      <td>view</td>\n",
       "      <td>78144</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756099</th>\n",
       "      <td>1438398530703</td>\n",
       "      <td>1184451</td>\n",
       "      <td>view</td>\n",
       "      <td>283392</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756100</th>\n",
       "      <td>1438400163914</td>\n",
       "      <td>199536</td>\n",
       "      <td>view</td>\n",
       "      <td>152913</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2756101 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  visitorid event  itemid  transactionid\n",
       "0        1433221332117     257597  view  355908            NaN\n",
       "1        1433224214164     992329  view  248676            NaN\n",
       "2        1433221999827     111016  view  318965            NaN\n",
       "3        1433221955914     483717  view  253185            NaN\n",
       "4        1433221337106     951259  view  367447            NaN\n",
       "...                ...        ...   ...     ...            ...\n",
       "2756096  1438398785939     591435  view  261427            NaN\n",
       "2756097  1438399813142     762376  view  115946            NaN\n",
       "2756098  1438397820527    1251746  view   78144            NaN\n",
       "2756099  1438398530703    1184451  view  283392            NaN\n",
       "2756100  1438400163914     199536  view  152913            NaN\n",
       "\n",
       "[2756101 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('https://s3.amazonaws.com//realityengines.exampledatasets/pers_promotion/events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "tGlnl2f7HByp",
    "outputId": "1b072ed5-3b28-4709-ec10-a0fc92430d2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>categoryid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>1171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>1244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59010</th>\n",
       "      <td>466847</td>\n",
       "      <td>1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59011</th>\n",
       "      <td>466848</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59012</th>\n",
       "      <td>466849</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59013</th>\n",
       "      <td>466858</td>\n",
       "      <td>1191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59014</th>\n",
       "      <td>466861</td>\n",
       "      <td>1051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59015 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       itemid  categoryid\n",
       "0          19        1171\n",
       "1          24        1244\n",
       "2          25          72\n",
       "3          40         160\n",
       "4          42          84\n",
       "...       ...         ...\n",
       "59010  466847        1221\n",
       "59011  466848        1250\n",
       "59012  466849         464\n",
       "59013  466858        1191\n",
       "59014  466861        1051\n",
       "\n",
       "[59015 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('https://s3.amazonaws.com//realityengines.exampledatasets/pers_promotion/item_categories.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mDVrJYKrzB9"
   },
   "source": [
    "Using the Create Dataset API, we can tell Abacus.AI the public S3 URI of where to find the datasets. We will also give each dataset a Refresh Schedule, which tells Abacus.AI when it should refresh the dataset (take an updated/latest copy of the dataset).\n",
    "\n",
    "If you're unfamiliar with Cron Syntax, Crontab Guru can help translate the syntax back into natural language: [https://crontab.guru/#0_12_\\*_\\*_\\*](https://crontab.guru/#0_12_*_*_*)\n",
    "\n",
    "**Note: This cron string will be evaluated in UTC time zone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oi6qwR46m71i"
   },
   "outputs": [],
   "source": [
    "user_item_dataset = client.create_dataset_from_file_connector(name='Retail Interaction Logs1',table_name='Retail_Interaction_Logs1',\n",
    "                                     location='s3://realityengines.datasets/pers_promotion/events.csv',\n",
    "                                     refresh_schedule='0 12 * * *')\n",
    "\n",
    "item_attributes_dataset = client.create_dataset_from_file_connector(name='Item Categories1',table_name='Item_Categories1',\n",
    "                                     location='s3://realityengines.exampledatasets/pers_promotion/item_categories.csv',\n",
    "                                     refresh_schedule='0 12 * * *')\n",
    "\n",
    "datasets = [user_item_dataset, item_attributes_dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Feature Groups and add them to your Project\n",
    "\n",
    "Datasets are created at the organization level and can be used to create feature groups as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group = client.create_feature_group(table_name='personalized_promotions',sql='SELECT * from Retail_Interaction_Logs11')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Feature Group to the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_feature_group_to_project(feature_group_id=feature_group.feature_group_id,project_id = promotions_project.project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the Feature Group type according to the use case requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_feature_group_type(feature_group_id=feature_group.feature_group_id, project_id = promotions_project.project_id, feature_group_type= \"USER_ITEM_INTERACTIONS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check current Feature Group schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Feature(name='timestamp',\n",
       "   select_clause=None,\n",
       "   feature_mapping=None,\n",
       "   source_table='Retail_Interaction_Logs11',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='TIMESTAMP',\n",
       "   data_type='DATETIME',\n",
       "   columns=None,\n",
       "   point_in_time_info=None),\n",
       " Feature(name='visitorid',\n",
       "   select_clause=None,\n",
       "   feature_mapping=None,\n",
       "   source_table='Retail_Interaction_Logs11',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='CATEGORICAL',\n",
       "   data_type='STRING',\n",
       "   columns=None,\n",
       "   point_in_time_info=None),\n",
       " Feature(name='event',\n",
       "   select_clause=None,\n",
       "   feature_mapping=None,\n",
       "   source_table='Retail_Interaction_Logs11',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='CATEGORICAL',\n",
       "   data_type='STRING',\n",
       "   columns=None,\n",
       "   point_in_time_info=None),\n",
       " Feature(name='itemid',\n",
       "   select_clause=None,\n",
       "   feature_mapping=None,\n",
       "   source_table='Retail_Interaction_Logs11',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='CATEGORICAL',\n",
       "   data_type='STRING',\n",
       "   columns=None,\n",
       "   point_in_time_info=None),\n",
       " Feature(name='transactionid',\n",
       "   select_clause=None,\n",
       "   feature_mapping=None,\n",
       "   source_table='Retail_Interaction_Logs11',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='CATEGORICAL',\n",
       "   data_type='STRING',\n",
       "   columns=None,\n",
       "   point_in_time_info=None)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_feature_group_schema(feature_group_id=feature_group.feature_group_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each **Use Case**, there are special **Column Mappings** that must be applied to a column to fulfill use case requirements. We can find the list of available **Column Mappings** by calling the *Describe Use Case Requirements* API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bp9E-YUym-Fr",
    "outputId": "5e896d8c-4568-4e89-fb1a-b18086d3bc59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ITEM_ID': {'description': 'This is the unique identifier of each item in your catalog. This is typically your product id, article id, or the video id.',\n",
       "  'allowed_feature_types': ['CATEGORICAL'],\n",
       "  'required': True},\n",
       " 'USER_ID': {'description': 'This is a unique identifier of each user in your user base.',\n",
       "  'allowed_feature_types': ['CATEGORICAL'],\n",
       "  'required': True},\n",
       " 'ACTION_TYPE': {'description': 'This is an optional column that specifies the type of action the user took. This could include any action that is specific to you (e.g., view, click, purchase, rating, comment, like, etc). You can always upload a dataset that has no action_type column if all the actions in the dataset are the same (e.g., a dataset of only purchases or clicks).',\n",
       "  'allowed_feature_types': ['CATEGORICAL'],\n",
       "  'required': False},\n",
       " 'TIMESTAMP': {'description': 'The timestamp when a particular action occurred.',\n",
       "  'allowed_feature_types': ['TIMESTAMP'],\n",
       "  'required': False},\n",
       " 'ACTION_WEIGHT': {'description': 'This is an optional column that specifies the weight of the action (e.g., video watch time, price of item purchased). This is used to optimize the the model to maximize actions with this value.',\n",
       "  'allowed_feature_types': ['NUMERICAL'],\n",
       "  'required': False},\n",
       " 'IGNORE': {'description': 'Ignore this column in training',\n",
       "  'multiple': True,\n",
       "  'required': False}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.describe_use_case_requirements(use_case)[0].allowed_feature_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Feature(name='timestamp',\n",
       "   select_clause=None,\n",
       "   feature_mapping='TIMESTAMP',\n",
       "   source_table='Retail_Interaction_Logs11',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='TIMESTAMP',\n",
       "   data_type='DATETIME',\n",
       "   columns=None,\n",
       "   point_in_time_info=None),\n",
       " Feature(name='visitorid',\n",
       "   select_clause=None,\n",
       "   feature_mapping='USER_ID',\n",
       "   source_table='Retail_Interaction_Logs11',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='CATEGORICAL',\n",
       "   data_type='STRING',\n",
       "   columns=None,\n",
       "   point_in_time_info=None),\n",
       " Feature(name='event',\n",
       "   select_clause=None,\n",
       "   feature_mapping=None,\n",
       "   source_table='Retail_Interaction_Logs11',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='CATEGORICAL',\n",
       "   data_type='STRING',\n",
       "   columns=None,\n",
       "   point_in_time_info=None),\n",
       " Feature(name='itemid',\n",
       "   select_clause=None,\n",
       "   feature_mapping='ITEM_ID',\n",
       "   source_table='Retail_Interaction_Logs11',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='CATEGORICAL',\n",
       "   data_type='STRING',\n",
       "   columns=None,\n",
       "   point_in_time_info=None),\n",
       " Feature(name='transactionid',\n",
       "   select_clause=None,\n",
       "   feature_mapping=None,\n",
       "   source_table='Retail_Interaction_Logs11',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='CATEGORICAL',\n",
       "   data_type='STRING',\n",
       "   columns=None,\n",
       "   point_in_time_info=None)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.set_feature_mapping(project_id = promotions_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='itemid',feature_mapping='ITEM_ID')\n",
    "client.set_feature_mapping(project_id = promotions_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='visitorid',feature_mapping='USER_ID')\n",
    "client.set_feature_mapping(project_id = promotions_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='timestamp',feature_mapping='TIMESTAMP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each required Feature Group Type within the use case, you must assign the Feature group to be used for training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.use_feature_group_for_training(project_id=promotions_project.project_id, feature_group_id=feature_group.feature_group_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-z1az5jqsFlA"
   },
   "source": [
    "Now that we've our feature groups assigned, we're almost ready to train a model!\n",
    "\n",
    "To be sure that our project is ready to go, let's call project.validate to confirm that all the project requirements have been met:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QfCrWMC1nAQh",
    "outputId": "3b8467e0-c877-41fe-a36d-38850165cd50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProjectValidation(valid=True,\n",
       "  dataset_errors=[],\n",
       "  column_hints={})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promotions_project.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbIqzNsjsESI"
   },
   "source": [
    "## 4. Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6Pf5VUwsG0C"
   },
   "source": [
    "For each **Use Case**, Abacus.AI has a bunch of options for training. We can call the *Get Training Config Options* API to see the available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4MGcC4fnBeG",
    "outputId": "a5b14e9e-0aea-4d76-8b64-fe70993d90cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TrainingConfigOptions(name='TEST_SPLIT',\n",
       "   data_type='INTEGER',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [5, 20]},\n",
       "   description='Percent of dataset to use for test data. We support using a range between 6% to 20% of your dataset to use as test data.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='DROPOUT_RATE',\n",
       "   data_type='INTEGER',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [0, 90]},\n",
       "   description='Dropout percentage rate.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='BATCH_SIZE',\n",
       "   data_type='ENUM',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'values': [8, 16, 32, 64, 128, 256, 384, 512, 740, 1024]},\n",
       "   description='Batch size.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='SKIP_HISTORY_FILTERING',\n",
       "   data_type='BOOLEAN',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=False,\n",
       "   options=None,\n",
       "   description='Do not remove items which have past interactions from recommendations.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='MAX_HISTORY_LENGTH',\n",
       "   data_type='INTEGER',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [0, 200]},\n",
       "   description='Maximum length of user-item history to include user in training examples.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='USE_ITEM_ATTRIBUTE_BUCKETING',\n",
       "   data_type='BOOLEAN',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options=None,\n",
       "   description='Prefer recommending items which have attribute similarity. Useful when we have natural item categories which are related, like e-commerce categories.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='UNORDERED_HISTORY',\n",
       "   data_type='BOOLEAN',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=False,\n",
       "   options=None,\n",
       "   description='Order of user item interactions is not important.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='MAX_USER_HISTORY_LEN_PERCENTILE',\n",
       "   data_type='INTEGER',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [95, 100]},\n",
       "   description='Filter out users with history length above this percentile.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='DOWNSAMPLE_ITEM_POPULARITY_PERCENTILE',\n",
       "   data_type='DECIMAL',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [0.1, 1.0]},\n",
       "   description='Downsample items more popular than this percentile.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='RECENT_DAYS_FOR_TRAINING',\n",
       "   data_type='INTEGER',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [1, 1000]},\n",
       "   description='Limit training data to a certain latest number of days.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='TRAINING_START_DATE',\n",
       "   data_type='DATETIME',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options=None,\n",
       "   description='Only consider training interaction data after this date. Specified in the timezone of the dataset.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='TEST_ON_USER_SPLIT',\n",
       "   data_type='BOOLEAN',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=False,\n",
       "   options=None,\n",
       "   description='Use user splits instead of using time splits, when validating and testing the model.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='TRAINING_CANDIDATE_ITEMS_LIMIT',\n",
       "   data_type='INTEGER',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [1000, 150000]},\n",
       "   description='Limit training data to these many \"best performing\" items. We use target events and weights to calculate it',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='MIN_INTERACTIONS',\n",
       "   data_type='INTEGER',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [0, 10000]},\n",
       "   description='Select candidate items with at least this many interactions.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='MIN_TARGET_INTERACTIONS',\n",
       "   data_type='INTEGER',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [0, 10000]},\n",
       "   description='Select candidate items with at least this many target interactions.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='CANDIDATE_SELECTION_TARGET_RATE_SCORING',\n",
       "   data_type='BOOLEAN',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=False,\n",
       "   options=None,\n",
       "   description='Use the rate of target events to select the candidates instead of the total score. Use this to make sure new items are considered in the selection',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='CANDIDATE_SELECTION_MAX_OTHER_EVENT_RATE',\n",
       "   data_type='DECIMAL',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options=None,\n",
       "   description='To prevent selecting outliers, cap the rate of target events (which are not part of session events) for candidate items to not exceed this value',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='SEARCH_QUERY_COLUMN',\n",
       "   data_type='ENUM',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'values': ['event', 'transactionid']},\n",
       "   description='Column which specifies a search query term that will be used for personalization.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='EXPLORE_LOOKBACK_HOURS',\n",
       "   data_type='DECIMAL',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [1, 168]},\n",
       "   description='Number of hours since creation time that an item is eligiblefor explore fraction.',\n",
       "   required=None,\n",
       "   last_model_value=None)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promotions_project.get_training_config_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbY-wWOMsIXW"
   },
   "source": [
    "In this notebook, we'll just train with the default options, but definitely feel free to experiment, especially if you have familiarity with Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZleD66xQnCY_",
    "outputId": "e3b7ed44-8851-42fc-e4c2-f766eabb6540"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Personalized Promotions Project Model',\n",
       " 'model_id': '2e8901150',\n",
       " 'model_config': {},\n",
       " 'created_at': '2021-11-24T19:26:15+00:00',\n",
       " 'project_id': '1e58b9d68',\n",
       " 'shared': False,\n",
       " 'shared_at': None,\n",
       " 'train_function_name': None,\n",
       " 'predict_function_name': None,\n",
       " 'training_input_tables': None,\n",
       " 'source_code': None,\n",
       " 'location': None,\n",
       " 'refresh_schedules': None,\n",
       " 'latest_model_version': {'model_version': '9d245170e',\n",
       "  'status': 'PENDING',\n",
       "  'model_id': '2e8901150',\n",
       "  'model_config': {},\n",
       "  'training_started_at': None,\n",
       "  'training_completed_at': None,\n",
       "  'dataset_versions': None,\n",
       "  'error': None,\n",
       "  'pending_deployment_ids': None,\n",
       "  'failed_deployment_ids': None}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promotions_model = promotions_project.train_model(training_config={})\n",
    "promotions_model.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcyVzLPusJ-A"
   },
   "source": [
    "After we start training the model, we can call this blocking call that routinely checks the status of the model until it is trained and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "RVEBK_UenDXB"
   },
   "outputs": [],
   "source": [
    "promotions_model.wait_for_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeV3j-ArPWY_"
   },
   "source": [
    "**Note that model training might take some minutes to some hours depending upon the size of datasets, complexity of the models being trained and a variety of other factors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xze5D2EYsLzZ"
   },
   "source": [
    "## **Checkpoint** [Optional]\n",
    "As model training can take an hours to complete, your page could time out or you might end up hitting the refresh button, this section helps you restore your progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6jh1W0wsNE4",
    "outputId": "ecce6fe6-752e-456c-a898-d48f9e514295"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(name='Personalized Promotions Project Model',\n",
       "  model_id='2e8901150',\n",
       "  model_config={},\n",
       "  created_at='2021-11-24T19:26:15+00:00',\n",
       "  project_id='1e58b9d68',\n",
       "  shared=False,\n",
       "  shared_at=None,\n",
       "  train_function_name=None,\n",
       "  predict_function_name=None,\n",
       "  training_input_tables=None,\n",
       "  source_code=None,\n",
       "  location=None,\n",
       "  refresh_schedules=None,\n",
       "  latest_model_version=ModelVersion(model_version='9d245170e',\n",
       "  status='COMPLETE',\n",
       "  model_id='2e8901150',\n",
       "  model_config={},\n",
       "  training_started_at='2021-11-24T19:31:03+00:00',\n",
       "  training_completed_at='2021-11-24T21:55:59+00:00',\n",
       "  dataset_versions=['9cb5fcb96'],\n",
       "  error=None,\n",
       "  pending_deployment_ids=[],\n",
       "  failed_deployment_ids=[]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install abacusai\n",
    "import pandas as pd\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "api_key = '2fdecde877dc45fab937eff82b70eff0'  #@param {type: \"string\"}\n",
    "from abacusai import ApiClient\n",
    "client = ApiClient(api_key)\n",
    "promotions_project = next(project for project in client.list_projects() if project.name == 'Personalized Promotions Project')\n",
    "promotions_model = promotions_project.list_models()[-1]\n",
    "promotions_model.wait_for_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOWvGxcGsYcz"
   },
   "source": [
    "## Evaluate your Model Metrics\n",
    "\n",
    "After your model is done training you can inspect the model's quality by reviewing the model's metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I0CLG0L1nE6k",
    "outputId": "4ddcbf86-3761-4e3b-8048-8792b64b8d5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'baseline_metrics': None,\n",
      "  'metrics': { 'coverage': 0.028666666666666667,\n",
      "               'map': 0.0078014435264858765,\n",
      "               'map@10': 0.006725259920634921,\n",
      "               'map@5': 0.006077888888888889,\n",
      "               'mrr': 0.009566456729611402,\n",
      "               'ndcg': 0.01694423470519298,\n",
      "               'ndcg@10': 0.01107502017794698,\n",
      "               'ndcg@5': 0.0088031855411701,\n",
      "               'personalization@10': 0.22458635663566143},\n",
      "  'model_id': '2e8901150',\n",
      "  'model_version': '9d245170e',\n",
      "  'target_column': None}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(promotions_model.get_metrics().to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arkoHs6JsZ_5"
   },
   "source": [
    "To get a better understanding on what these metrics mean, visit our [documentation](https://abacus.ai/app/help/useCases/PERS_PROMOTIONS/training) page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qN6zws9rsezV"
   },
   "source": [
    "## 4. Deploy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Id2AlJLJsgET"
   },
   "source": [
    "After the model has been trained, we need to deploy the model to be able to start making predictions. Deploying a model will reserve cloud resources to host the model for Realtime and/or batch predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2IVYnjlvnF5F",
    "outputId": "980c84d5-3842-4a7b-9b5c-e95af4ff68b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deployment(deployment_id='1428f4669a',\n",
       "  name='Personalized Promotions Deployment',\n",
       "  status='ACTIVE',\n",
       "  description='Personalized Promotions Deployment',\n",
       "  deployed_at='2021-11-24T22:10:56+00:00',\n",
       "  created_at='2021-11-24T22:10:17+00:00',\n",
       "  project_id='1e58b9d68',\n",
       "  model_id='2e8901150',\n",
       "  model_version='9d245170e',\n",
       "  feature_group_id=None,\n",
       "  feature_group_version=None,\n",
       "  calls_per_second=5,\n",
       "  auto_deploy=True,\n",
       "  regions=[{'name': 'Us East 1', 'value': 'us-east-1'}],\n",
       "  error=None,\n",
       "  refresh_schedules=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promotions_deployment = client.create_deployment(name='Personalized Promotions Deployment',model_id=promotions_model.model_id,description='Personalized Promotions Deployment')\n",
    "promotions_deployment.wait_for_deployment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmXL_efDshep"
   },
   "source": [
    "After the model is deployed, we need to create a deployment token for authenticating prediction requests. This token is only authorized to predict on deployments in this project, so it's safe to embed this token inside of a user-facing application or website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "JAbYOMDHnG_F",
    "outputId": "82d6ae34-e5ab-4c39-abe8-d3f7d648d899"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5a8e28cc457842fa97c390eb3e126779'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_token = promotions_project.create_deployment_token().deployment_token\n",
    "deployment_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMk0g7Nksi11"
   },
   "source": [
    "## 5. Predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ugj0m1BAskZq"
   },
   "source": [
    "Now that you have an active deployment and a deployment token to authenticate requests, you can make the `get_personalized_ranking` API call below.\n",
    "\n",
    "This command will return a list with each specified item ID ranked according to the specified visitor's preferences. The ranking would be performed based on what movies the user liked in the past and how the movies and users are related to each other depending on their attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cpudWxY3nH9r",
    "outputId": "5fb86df3-373a-4f69-90d6-3492f0b63c71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'itemid': '181204'},\n",
       " {'itemid': '339763'},\n",
       " {'itemid': '344603'},\n",
       " {'itemid': '385091'},\n",
       " {'itemid': '424193'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ApiClient().get_personalized_ranking(deployment_token=deployment_token,\n",
    "                                     deployment_id=promotions_deployment.deployment_id,\n",
    "                                     query_data={\"visitorid\":\"100018\",\"itemid\":[\"424193\",\"181204\",\"385091\",\"339763\",\"344603\"]})"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Personalized Promotions Notebook.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
