{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "798Rf5S52cJM"
   },
   "source": [
    "## How-to guide for Cloud Spend use-case on Abacus.AI platform\n",
    "This notebook provides you with a hands on environment to build an cloud spend alert model using the Abacus.AI Python Client Library.\n",
    "\n",
    "We'll be using the [Cloud Spend Dataset](https://s3.amazonaws.com//realityengines.exampledatasets/cloud_operations/cloud_spend.csv), which, as the name suggests, contains information about cloud spends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "--mZuKj93z18"
   },
   "source": [
    "1. Install the Abacus.AI library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7488,
     "status": "ok",
     "timestamp": 1596566808039,
     "user": {
      "displayName": "Ashni Sheth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5hwKgDpwIJPCrdFXQB60XSkRPTEWGv9jeKLpnMo0=s64",
      "userId": "15098545459592232887"
     },
     "user_tz": 420
    },
    "id": "x1rd5a6Hyx0a",
    "outputId": "2ba02992-a418-455a-87af-a0e46769be5d"
   },
   "outputs": [],
   "source": [
    "!pip install abacusai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aqte63CZ351O"
   },
   "source": [
    "We'll also import pandas and pprint tools for visualization in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mSaBA5WzzoNl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # A tool we'll use to download and preview CSV files\n",
    "import pprint # A tool to pretty print dictionary outputs\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c_0en-0w3-H8"
   },
   "source": [
    "2. Add your Abacus.AI [API Key](https://abacus.ai/app/profile/apikey) generated using the API dashboard as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_vxWCivxzqSo"
   },
   "outputs": [],
   "source": [
    "#@title Abacus.AI API Key\n",
    "\n",
    "api_key = ''  #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4T2t6nbU4Jfv"
   },
   "source": [
    "3. Import the Abacus.AI library and instantiate a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQdlAX0uztIT"
   },
   "outputs": [],
   "source": [
    "from abacusai import ApiClient\n",
    "client = ApiClient(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "czQai9Qn4Lom"
   },
   "source": [
    "## 1. Create a Project\n",
    "\n",
    "Abacus.AI projects are containers that have datasets and trained models. By specifying a business **Use Case**, Abacus.AI tailors the deep learning algorithms to produce the best performing model catered specifically for your data.\n",
    "\n",
    "We'll call the `list_use_cases` method to retrieve a list of the Use Cases currently available on the Abacus.AI platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6268,
     "status": "ok",
     "timestamp": 1596566809778,
     "user": {
      "displayName": "Ashni Sheth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5hwKgDpwIJPCrdFXQB60XSkRPTEWGv9jeKLpnMo0=s64",
      "userId": "15098545459592232887"
     },
     "user_tz": 420
    },
    "id": "b1mop7blz7P2",
    "outputId": "8d310459-c71e-4861-c3b6-01130b44dc68"
   },
   "outputs": [],
   "source": [
    "client.list_use_cases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dyNpJwSC4OWp"
   },
   "source": [
    "In this notebook, we're going to create a cloud spend alert model using the Cloud Spend dataset. The 'OPERATIONS_CLOUD' use case is best tailored for this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dwczQf84z_6A"
   },
   "outputs": [],
   "source": [
    "#@title Abacus.AI Use Case\n",
    "\n",
    "use_case = 'OPERATIONS_CLOUD'  #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4vj6gAnf4X54"
   },
   "source": [
    "By calling the `describe_use_case_requirements` method we can view what datasets are required for this use_case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1199,
     "status": "ok",
     "timestamp": 1596566811003,
     "user": {
      "displayName": "Ashni Sheth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5hwKgDpwIJPCrdFXQB60XSkRPTEWGv9jeKLpnMo0=s64",
      "userId": "15098545459592232887"
     },
     "user_tz": 420
    },
    "id": "t81mQJzz0JPX",
    "outputId": "dc189e58-8b68-48f9-b30e-36816419918c"
   },
   "outputs": [],
   "source": [
    "for requirement in client.describe_use_case_requirements(use_case):\n",
    "  pp.pprint(requirement.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yi9sWxXS4c5x"
   },
   "source": [
    "Finally, let's create the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 896,
     "status": "ok",
     "timestamp": 1596566812527,
     "user": {
      "displayName": "Ashni Sheth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5hwKgDpwIJPCrdFXQB60XSkRPTEWGv9jeKLpnMo0=s64",
      "userId": "15098545459592232887"
     },
     "user_tz": 420
    },
    "id": "_7PREqP80Nn7",
    "outputId": "40ee444c-fc3a-4fae-cc30-318d1e444d6b"
   },
   "outputs": [],
   "source": [
    "cloud_project = client.create_project(name='Cloud Spend Project', use_case=use_case)\n",
    "cloud_project.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QD-SqIiQ4hQK"
   },
   "source": [
    "## 2. Add Datasets to your Project\n",
    "\n",
    "Abacus.AI can read datasets directly from `AWS S3` or `Google Cloud Storage` buckets, otherwise you can also directly upload and store your datasets with Abacus.AI. For this notebook, we will have Abacus.AI read the datasets directly from a public S3 bucket's location.\n",
    "\n",
    "We are using one dataset for this notebook. We'll tell Abacus.AI how the dataset should be used when creating it by tagging the dataset with a special Abacus.AI **Dataset Type**.\n",
    "- [Cloud Spend Dataset](https://s3.amazonaws.com//realityengines.exampledatasets/cloud_operations/cloud_spend.csv) (**TIMESERIES**): \n",
    "This dataset contains information about a company's cloud expenses, including the start date, service, and log cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bHDCJryc5CNj"
   },
   "source": [
    "### Add the dataset to Abacus.AI\n",
    "\n",
    "First we'll use Pandas to preview the file, then add it to Abacus.AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1903,
     "status": "ok",
     "timestamp": 1596566817420,
     "user": {
      "displayName": "Ashni Sheth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5hwKgDpwIJPCrdFXQB60XSkRPTEWGv9jeKLpnMo0=s64",
      "userId": "15098545459592232887"
     },
     "user_tz": 420
    },
    "id": "LdUfs-Zp15Xp",
    "outputId": "36b2ac6f-4e66-4004-a708-4f8bbe5db817"
   },
   "outputs": [],
   "source": [
    "pd.read_csv('https://s3.amazonaws.com//realityengines.exampledatasets/cloud_operations/cloud_spend.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-3GYhCn5DQg"
   },
   "source": [
    "Using the Create Dataset API, we can tell Abacus.AI the public S3 URI of where to find the datasets. We will also give each dataset a Refresh Schedule, which tells Abacus.AI when it should refresh the dataset (take an updated/latest copy of the dataset).\n",
    "\n",
    "If you're unfamiliar with Cron Syntax, Crontab Guru can help translate the syntax back into natural language: [https://crontab.guru/#0_12_\\*_\\*_\\*](https://crontab.guru/#0_12_*_*_*)\n",
    "\n",
    "**Note: This cron string will be evaluated in UTC time zone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rx2-HfHagdr4"
   },
   "outputs": [],
   "source": [
    "cloud_dataset = client.create_dataset('Cloud Spend', \n",
    "                                     location='s3://realityengines.exampledatasets/cloud_operations/cloud_spend.csv',\n",
    "                                     project_id=cloud_project.project_id, \n",
    "                                     dataset_type='TIMESERIES',\n",
    "                                     refresh_schedule='0 12 * * *')\n",
    "datasets = [cloud_dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fFaLm-ZN5J1l"
   },
   "source": [
    "### Check dataset processing status and get dataset schemas when processing finishes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2003,
     "status": "ok",
     "timestamp": 1596569088135,
     "user": {
      "displayName": "Ashni Sheth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5hwKgDpwIJPCrdFXQB60XSkRPTEWGv9jeKLpnMo0=s64",
      "userId": "15098545459592232887"
     },
     "user_tz": 420
    },
    "id": "JEk_zC4Sgzjj",
    "outputId": "c8362ebc-9ecc-4ed1-b75a-96df3d1ead64"
   },
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    dataset.wait_for_inspection()\n",
    "    print(f'{dataset.name} Schema:')\n",
    "    pp.pprint(client.get_schema(cloud_project.project_id, dataset.dataset_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qp-N6ZhZ5KeI"
   },
   "source": [
    "Each column in a **Dataset** is associated with a **Column Data Type**.\n",
    "All we need to do now is to tell Abacus.AI what field we want to predict from our **Dataset**.\n",
    "\n",
    "For each **Dataset Type** in a **Use Case**, there are special **Column Mappings** that can be applied to a column. We can find the list of available **Column Mappings** by calling the *Describe Use Case Requirements* API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1234,
     "status": "ok",
     "timestamp": 1596569091011,
     "user": {
      "displayName": "Ashni Sheth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5hwKgDpwIJPCrdFXQB60XSkRPTEWGv9jeKLpnMo0=s64",
      "userId": "15098545459592232887"
     },
     "user_tz": 420
    },
    "id": "1SeqQIzWZCER",
    "outputId": "e95c3366-1f04-4f6d-9551-7b5d5276d65f"
   },
   "outputs": [],
   "source": [
    "client.describe_use_case_requirements(use_case)[0].allowed_column_mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mlW3lUXE5Ou9"
   },
   "source": [
    "We would map the *service* column as **SERVICE_ID**, the *LogCost* column as **VALUE**, and the *UsageStartDate* column as **DATE**.\n",
    "\n",
    "The result of this call will be the updated schema after the **Column Mapping** is applied as stated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1423,
     "status": "ok",
     "timestamp": 1596569093214,
     "user": {
      "displayName": "Ashni Sheth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5hwKgDpwIJPCrdFXQB60XSkRPTEWGv9jeKLpnMo0=s64",
      "userId": "15098545459592232887"
     },
     "user_tz": 420
    },
    "id": "z597ugVF5Ph8",
    "outputId": "7b079a9c-b9bf-453b-e378-f79e0ee21063"
   },
   "outputs": [],
   "source": [
    "client.set_column_mapping(project_id=cloud_project.project_id, dataset_id=cloud_dataset.dataset_id,\n",
    "                          column='service', column_mapping='SERVICE_ID')\n",
    "\n",
    "client.set_column_mapping(project_id=cloud_project.project_id, dataset_id=cloud_dataset.dataset_id,\n",
    "                          column='LogCost', column_mapping='VALUE')\n",
    "\n",
    "client.set_column_mapping(project_id=cloud_project.project_id, dataset_id=cloud_dataset.dataset_id,\n",
    "                          column='UsageStartDate', column_mapping='DATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s-FIyjbX5x_b"
   },
   "source": [
    "## 3. Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j_oPioRB5yQf"
   },
   "source": [
    "Now that we've uploaded the datasets, we're almost ready to train a model!\n",
    "\n",
    "To be sure that our project is ready to go, let's call `project.validate` to confirm that all the project requirements have been met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 981,
     "status": "ok",
     "timestamp": 1596569096844,
     "user": {
      "displayName": "Ashni Sheth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5hwKgDpwIJPCrdFXQB60XSkRPTEWGv9jeKLpnMo0=s64",
      "userId": "15098545459592232887"
     },
     "user_tz": 420
    },
    "id": "EtB15JT9ZrVW",
    "outputId": "df77bfac-a94a-47bb-eb76-123134459c8a"
   },
   "outputs": [],
   "source": [
    "cloud_project.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PrYxMfrP52g5"
   },
   "source": [
    "For each **Use Case**, Abacus.AI has a bunch of options for training. We can call the *Get Training Config Options* API to see the available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 902,
     "status": "ok",
     "timestamp": 1596569099991,
     "user": {
      "displayName": "Ashni Sheth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5hwKgDpwIJPCrdFXQB60XSkRPTEWGv9jeKLpnMo0=s64",
      "userId": "15098545459592232887"
     },
     "user_tz": 420
    },
    "id": "bxnw7no0Zvaj",
    "outputId": "5512c8cf-1b27-4caa-d7ea-78acf1109b46"
   },
   "outputs": [],
   "source": [
    "cloud_project.get_training_config_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1oopEwk54xD"
   },
   "source": [
    "In this notebook, we'll just train with the default options, but definitely feel free to experiment, especially if you have familiarity with Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1235,
     "status": "ok",
     "timestamp": 1596569103347,
     "user": {
      "displayName": "Ashni Sheth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5hwKgDpwIJPCrdFXQB60XSkRPTEWGv9jeKLpnMo0=s64",
      "userId": "15098545459592232887"
     },
     "user_tz": 420
    },
    "id": "w2Uy6IgIZy8I",
    "outputId": "ad2da8db-bfb5-4f78-df67-4702772b64d1"
   },
   "outputs": [],
   "source": [
    "cloud_model = cloud_project.train_model(training_config={})\n",
    "cloud_model.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JfTu53sI59SJ"
   },
   "source": [
    "After we start training the model, we can call this blocking call that routinely checks the status of the model until it is trained and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1202125,
     "status": "ok",
     "timestamp": 1596571844100,
     "user": {
      "displayName": "Ashni Sheth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5hwKgDpwIJPCrdFXQB60XSkRPTEWGv9jeKLpnMo0=s64",
      "userId": "15098545459592232887"
     },
     "user_tz": 420
    },
    "id": "ZsSIe5Gbb5El",
    "outputId": "333752cd-9149-426c-faae-5358af95c296"
   },
   "outputs": [],
   "source": [
    "cloud_model.wait_for_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uv9RckJr6AFQ"
   },
   "source": [
    "## **(Checkpoint)**\n",
    "Training can take an hour or two to complete, but we encourage you to run the remaining calls on your own time. If your page times out or you hit refresh, you can restore your progress in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-O6jEpvi6Dnm"
   },
   "outputs": [],
   "source": [
    "!pip install abacusai\n",
    "import pandas as pd\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "api_key = ''  #@param {type: \"string\"}\n",
    "from abacusai import ApiClient\n",
    "client = ApiClient(api_key)\n",
    "cloud_project = next(project for project in client.list_projects() if project.name == 'Cloud Spend Project')\n",
    "cloud_model = cloud_project.list_models()[-1]\n",
    "cloud_model.wait_for_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e5CeWns16Of6"
   },
   "source": [
    "## Evaluate your Model Metrics\n",
    "\n",
    "After your model is done training you can inspect the model's quality by reviewing the model's metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 671,
     "status": "ok",
     "timestamp": 1596572936753,
     "user": {
      "displayName": "Ashni Sheth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5hwKgDpwIJPCrdFXQB60XSkRPTEWGv9jeKLpnMo0=s64",
      "userId": "15098545459592232887"
     },
     "user_tz": 420
    },
    "id": "ssQeRUTBaZlx",
    "outputId": "55a7f1ac-b33b-453f-bfaa-a422c1cbc532"
   },
   "outputs": [],
   "source": [
    "pp.pprint(cloud_model.get_metrics().to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ICiIimPs6Qnn"
   },
   "source": [
    "To get a better understanding on what these metrics mean, visit our [documentation](https://abacus.ai/app/help/useCases/OPERATIONS_CLOUD/training) page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_SXHfF346Wyb"
   },
   "source": [
    "## 4. Deploy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "II_0L3_c6XFU"
   },
   "source": [
    "After the model has been trained, we need to deploy the model to be able to start making predictions. Deploying a model will reserve cloud resources to host the model for Realtime and/or batch predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54930,
     "status": "ok",
     "timestamp": 1596572993412,
     "user": {
      "displayName": "Ashni Sheth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5hwKgDpwIJPCrdFXQB60XSkRPTEWGv9jeKLpnMo0=s64",
      "userId": "15098545459592232887"
     },
     "user_tz": 420
    },
    "id": "vGgpYiyscQ8T",
    "outputId": "1f51dac3-4c3c-47bf-d946-738e05fb18d6"
   },
   "outputs": [],
   "source": [
    "cloud_deployment = cloud_model.create_deployment('Cloud Spend Deployment')\n",
    "cloud_deployment.wait_for_deployment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GcF-p-9u6anF"
   },
   "source": [
    "After the model is deployed, we need to create a deployment token for authenticating prediction requests. This token is only authorized to predict on deployments in this project, so it's safe to embed this token inside of a user-facing application or website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1172,
     "status": "ok",
     "timestamp": 1596573003752,
     "user": {
      "displayName": "Ashni Sheth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5hwKgDpwIJPCrdFXQB60XSkRPTEWGv9jeKLpnMo0=s64",
      "userId": "15098545459592232887"
     },
     "user_tz": 420
    },
    "id": "dRybQyY6cilt",
    "outputId": "79135cb2-2101-4ae6-c43d-c3a4c2aa212c"
   },
   "outputs": [],
   "source": [
    "deployment_token = cloud_project.create_deployment_token().deployment_token\n",
    "deployment_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gyAkodtr6czT"
   },
   "source": [
    "## 5. Predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4g4bWvWU6dMo"
   },
   "source": [
    "Now that you have an active deployment and a deployment token to authenticate requests, you can make the `get_anomalies` API call below.\n",
    "\n",
    "This command will return information about a company's cloud spending, including the threshold, service, and anomalies. The anomaly detection would be performed using the data in the Cloud Spend dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14556,
     "status": "ok",
     "timestamp": 1596573038983,
     "user": {
      "displayName": "Ashni Sheth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5hwKgDpwIJPCrdFXQB60XSkRPTEWGv9jeKLpnMo0=s64",
      "userId": "15098545459592232887"
     },
     "user_tz": 420
    },
    "id": "kMfeKzvdcmHv",
    "outputId": "e9b73e12-9a32-496f-b89e-6cc5c036efa4"
   },
   "outputs": [],
   "source": [
    "ApiClient().get_anomalies(deployment_token=deployment_token, \n",
    "               deployment_id=cloud_deployment.deployment_id)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMa3O4WlormQvH0koN5L1rw",
   "collapsed_sections": [],
   "name": "Cloud Spend Alerts Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
